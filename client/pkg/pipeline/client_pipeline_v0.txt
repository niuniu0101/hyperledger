package pipeline

import (
	"crypto/sha256"
	"encoding/binary"
)

// FileTask 表示一个待处理的文件任务
type FileTask struct {
	FileName string
	Data     []byte
	Size     int
	Node     string
	FileHash uint64
}

// HashFunc 计算节点名和哈希的函数签名
type HashFunc func(fileName string) (string, uint64)

// NodeCacheConfig 节点缓存配置
type NodeCacheConfig struct {
	DefaultCacheSize int
	nodeCacheSizes   map[string]int
}

func NewNodeCacheConfig(defaultSize int) *NodeCacheConfig {
	return &NodeCacheConfig{
		DefaultCacheSize: defaultSize,
		nodeCacheSizes:   make(map[string]int),
	}
}

func (c *NodeCacheConfig) SetNodeCacheSize(node string, size int) {
	c.nodeCacheSizes[node] = size
}

func (c *NodeCacheConfig) GetNodeCacheSize(node string) int {
	if size, ok := c.nodeCacheSizes[node]; ok {
		return size
	}
	return c.DefaultCacheSize
}

// ClientPipeline 客户端流水线结构（串行版本）
type ClientPipeline struct {
	// 节点缓存管理
	cacheMap    map[string][]*FileTask
	cacheConfig *NodeCacheConfig

	// 函数配置
	sendFunc func(node string, tasks []*FileTask)
	hashFunc HashFunc

	// 任务队列（串行处理）
	tasks []*FileTask
}

// NewClientPipeline 创建流水线
func NewClientPipeline(
	hashFunc HashFunc,
	sendFunc func(node string, tasks []*FileTask),
	defaultCacheSize int,
) *ClientPipeline {
	return &ClientPipeline{
		cacheMap:    make(map[string][]*FileTask),
		cacheConfig: NewNodeCacheConfig(defaultCacheSize),
		sendFunc:    sendFunc,
		hashFunc:    hashFunc,
		tasks:       make([]*FileTask, 0),
	}
}

// SetNodeCacheSize 设置特定节点的缓存大小
func (p *ClientPipeline) SetNodeCacheSize(node string, size int) {
	p.cacheConfig.SetNodeCacheSize(node, size)
}

// PushWorkload 添加工作负载（串行版本）
func (p *ClientPipeline) PushWorkload(fileName string, data []byte) {
	task := &FileTask{
		FileName: fileName,
		Data:     data,
		Size:     len(data),
	}
	p.tasks = append(p.tasks, task)
}

// processTask 处理单个任务（串行版本的核心逻辑）
func (p *ClientPipeline) processTask(task *FileTask) {
	// 1. 计算节点名和哈希
	node, fileHash := p.hashFunc(task.FileName)
	task.Node = node
	task.FileHash = fileHash

	// 2. 添加到节点缓存
	cache := p.cacheMap[task.Node]
	cache = append(cache, task)

	// 3. 检查是否需要发送
	if len(cache) >= p.cacheConfig.GetNodeCacheSize(task.Node) {
		// 缓存满了，立即发送
		p.sendFunc(task.Node, cache)
		p.cacheMap[task.Node] = nil // 清空缓存
	} else {
		// 更新缓存
		p.cacheMap[task.Node] = cache
	}
}

// FlushAll 强制发送所有未满的cache（串行版本）
func (p *ClientPipeline) FlushAll() {
	for node, cache := range p.cacheMap {
		if len(cache) > 0 {
			p.sendFunc(node, cache)
			p.cacheMap[node] = nil
		}
	}
}

// Wait 等待所有任务完成（串行版本）
func (p *ClientPipeline) Wait() {
	// 串行处理所有任务
	for _, task := range p.tasks {
		p.processTask(task)
	}

	// 处理完所有任务后，发送所有剩余的缓存
	p.FlushAll()

	// 清空任务列表
	p.tasks = p.tasks[:0]
}

// DefaultHashFunc 示例hashFunc实现
func DefaultHashFunc(hrm interface {
	LocateKey(ringID, fileName string) string
}, ringID string) HashFunc {
	return func(fileName string) (string, uint64) {
		hash := sha256.Sum256([]byte(fileName))
		fileHash := binary.BigEndian.Uint64(hash[:8])
		node := hrm.LocateKey(ringID, fileName)
		return node, fileHash
	}
}
