// ...existing code...
package pipeline

import (
	"crypto/sha256"
	"encoding/binary"
)

// FileTask 表示一个待处理的文件任务
type FileTask struct {
	FileName  string
	Data      []byte
	Size      int
	Node      string
	FileHash  uint64
	ShortName string
	Server    string
}

// HashFunc 计算节点名、哈希、截断文件名及服务器地址
type HashFunc func(fileName string) (node string, fileHash uint64, shortName string, server string)

// NodeCacheConfig 节点缓存配置
type NodeCacheConfig struct {
	DefaultCacheSize int
	nodeCacheSizes   map[string]int
}

func NewNodeCacheConfig(defaultSize int) *NodeCacheConfig {
	return &NodeCacheConfig{
		DefaultCacheSize: defaultSize,
		nodeCacheSizes:   make(map[string]int),
	}
}

func (c *NodeCacheConfig) SetNodeCacheSize(node string, size int) {
	c.nodeCacheSizes[node] = size
}

func (c *NodeCacheConfig) GetNodeCacheSize(node string) int {
	if size, ok := c.nodeCacheSizes[node]; ok {
		return size
	}
	return c.DefaultCacheSize
}

// ClientPipeline 客户端流水线结构（串行版本）
type ClientPipeline struct {
	cacheMap    map[string][]*FileTask
	cacheConfig *NodeCacheConfig

	sendFunc func(server string, node string, tasks []*FileTask)
	hashFunc HashFunc

	tasks []*FileTask
}

// NewClientPipeline 创建流水线
func NewClientPipeline(
	hashFunc HashFunc,
	sendFunc func(server string, node string, tasks []*FileTask),
	defaultCacheSize int,
) *ClientPipeline {
	return &ClientPipeline{
		cacheMap:    make(map[string][]*FileTask),
		cacheConfig: NewNodeCacheConfig(defaultCacheSize),
		sendFunc:    sendFunc,
		hashFunc:    hashFunc,
		tasks:       make([]*FileTask, 0),
	}
}

// SetNodeCacheSize 设置特定节点的缓存大小
func (p *ClientPipeline) SetNodeCacheSize(node string, size int) {
	p.cacheConfig.SetNodeCacheSize(node, size)
}

// PushWorkload 添加工作负载（串行版本）
func (p *ClientPipeline) PushWorkload(fileName string, data []byte) {
	task := &FileTask{
		FileName: fileName,
		Data:     data,
		Size:     len(data),
	}
	p.tasks = append(p.tasks, task)
}

// processTask 处理单个任务（串行版本的核心逻辑）
func (p *ClientPipeline) processTask(task *FileTask) {
	node, fileHash, shortName, server := p.hashFunc(task.FileName)
	if node == "" || server == "" {
		return
	}
	task.Node = node
	task.FileHash = fileHash
	task.ShortName = shortName
	task.Server = server

	cache := p.cacheMap[task.Node]
	if len(cache) > 0 && cache[0].Server != task.Server {
		p.sendFunc(cache[0].Server, task.Node, cache)
		cache = nil
	}

	cache = append(cache, task)

	if len(cache) >= p.cacheConfig.GetNodeCacheSize(task.Node) {
		p.sendFunc(task.Server, task.Node, cache)
		p.cacheMap[task.Node] = nil
	} else {
		p.cacheMap[task.Node] = cache
	}
}

// FlushAll 强制发送所有未满的cache（串行版本）
func (p *ClientPipeline) FlushAll() {
	for node, cache := range p.cacheMap {
		if len(cache) > 0 {
			p.sendFunc(cache[0].Server, node, cache)
			p.cacheMap[node] = nil
		}
	}
}

// Wait 等待所有任务完成（串行版本）
func (p *ClientPipeline) Wait() {
	for _, task := range p.tasks {
		p.processTask(task)
	}
	p.FlushAll()
	p.tasks = p.tasks[:0]
}

// DefaultHashFunc 示例hashFunc实现
func DefaultHashFunc(hrm interface {
	LocateKey(ringID, fileName string) string
}, ringID string, server string) HashFunc {
	return func(fileName string) (string, uint64, string, string) {
		shortName := fileName
		if len(shortName) > 16 {
			shortName = shortName[:16]
		}
		hash := sha256.Sum256([]byte(fileName))
		fileHash := binary.BigEndian.Uint64(hash[:8])
		node := hrm.LocateKey(ringID, shortName)
		return node, fileHash, shortName, server
	}
}
